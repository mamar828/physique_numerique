{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "aa6e8cf8",
   "metadata": {},
   "source": [
    "Simple Example Tutorial\n",
    "Constructing a GaussPy-Friendly Dataset\n",
    "\n",
    "Before implementing AGD, we first must put data into a format readable by GaussPy. GaussPy requires the indepenent and dependent spectral arrays (e.g., channels and amplitude) and an estimate of the per-channel noise in the specrum.\n",
    "\n",
    "To begin, we can create a simple Gaussian function of the form:\n",
    "\n",
    "(1)\n",
    "𝑆(𝑥𝑖)=∑𝑘=1𝙽𝙲𝙾𝙼𝙿𝚂𝙰𝙼𝙿𝑘exp[−4ln2(𝑥𝑖−𝙼𝙴𝙰𝙽𝑘)2𝙵𝚆𝙷𝙼2𝑘]+𝙽𝙾𝙸𝚂𝙴,𝑖=1,⋯,𝙽𝙲𝙷𝙰𝙽𝙽𝙴𝙻𝚂\n",
    "where,\n",
    "\n",
    "NCOMPS is the number of Gaussian components in each spectrum.\n",
    "(AMP, MEAN, FWHM) are the amplitude, mean location, and full-width-half-maximum of each Gaussian component.\n",
    "NCHANNELS is the number of channels in the spectrum (sets the resolution).\n",
    "NOISE is the level of noise introduced in each spectrum, described by the root mean square (RMS) noise per channel.\n",
    "In the next example we will show how to implement this in python. We have made the following assumptions:\n",
    "\n",
    "NCOMPS = 1 (to begin with a simple, single Gaussian)\n",
    "AMP = 1.0, MEAN = 256, FWHM = 20 (fixed Gaussian parameters)\n",
    "NCHANNELS = 512\n",
    "RMS = 0.05\n",
    "In the following figure we display the spectrum with the single Gaussian described above.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7f038c46",
   "metadata": {},
   "source": [
    "The following code describes an example of how to create a spectrum with a Gaussian shape and store the channels, amplitude and error arrays in a python pickle file to be read later by GaussPy.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "feb47f8c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create simple Gaussian profile with added noise\n",
    "# Store in format required for GaussPy\n",
    "\n",
    "import numpy as np\n",
    "import pickle\n",
    "\n",
    "# create a function which returns the values of the Gaussian function for a\n",
    "# given x\n",
    "def gaussian(amp, fwhm, mean):\n",
    "    return lambda x: amp * np.exp(-4. * np.log(2) * (x-mean)**2 / fwhm**2)\n",
    "\n",
    "# Data properties\n",
    "RMS = 0.05\n",
    "NCHANNELS = 512\n",
    "FILENAME = 'simple_gaussian.pickle'\n",
    "\n",
    "# Component properties\n",
    "AMP = 1.0\n",
    "FWHM = 20\n",
    "MEAN = 256\n",
    "\n",
    "# Initialize\n",
    "data = {}\n",
    "chan = np.arange(NCHANNELS)\n",
    "errors = np.ones(NCHANNELS) * RMS\n",
    "\n",
    "spectrum = np.random.randn(NCHANNELS) * RMS\n",
    "spectrum += gaussian(AMP, FWHM, MEAN)(chan)\n",
    "\n",
    "# Enter results into AGD dataset\n",
    "data['data_list'] = data.get('data_list', []) + [spectrum]\n",
    "data['x_values'] = data.get('x_values', []) + [chan]\n",
    "data['errors'] = data.get('errors', []) + [errors]\n",
    "\n",
    "pickle.dump(data, open(FILENAME, 'wb'))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1cc6548d",
   "metadata": {},
   "source": [
    "# Running GaussPy\n",
    "With our simple dataset in hand, we can use GaussPy to decompose the spectrum into Gaussian functions. To do this, we must specify the smoothing parameter 𝛼 (see Behind the Scenes chapter for more details). For now, we will guess a value of log𝛼=1. In later chapters we will discuss training the AGD algorithm to select the optimal value of 𝛼.\n",
    "\n",
    "The following is an example code for running GaussPy. We will use the “one-phase” decomposition to begin with. We must specify the following parameters:\n",
    "\n",
    "alpha1: our choice for the value of log𝛼.\n",
    "snr_thresh: the signal-to-noise ratio threshold below which amplitude GaussPy will not fit a component.\n",
    "FILENAME_DATA: the filename containing the dataset to-be-decomposed, constructed in the previous section (or any GaussPy-friendly dataset)\n",
    "FILENAME_DATA_DECOMP: filename to store the decomposition results from GaussPy.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f8063469",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Decompose simple dataset using AGD\n",
    "import pickle\n",
    "import projet.src.fitters.gausspy_lib.gp as gp\n",
    "\n",
    "# Specify necessary parameters\n",
    "alpha1 = 1.\n",
    "snr_thresh = 5.\n",
    "FILENAME_DATA = 'simple_gaussian.pickle'\n",
    "FILENAME_DATA_DECOMP = 'simple_gaussian_decomposed.pickle'\n",
    "\n",
    "# Load GaussPy\n",
    "g = gp.GaussianDecomposer()\n",
    "\n",
    "# Setting AGD parameters\n",
    "g.set('phase', 'one')\n",
    "g.set('SNR_thresh', [snr_thresh, snr_thresh])\n",
    "g.set('alpha1', alpha1)\n",
    "\n",
    "# Run GaussPy\n",
    "data_decomp = g.batch_decomposition(FILENAME_DATA)\n",
    "\n",
    "# Save decomposition information\n",
    "pickle.dump(data_decomp, open(FILENAME_DATA_DECOMP, 'wb'))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "202d1176",
   "metadata": {},
   "source": [
    "After AGD determines the Gaussian decomposition, GaussPy then performs a least squares fit of the inital AGD model to the data to produce a final fit solution. The file containing the fit results is a python pickle file. The contents of this file can be viewed by printing the keys within the saved dictionary via,\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f128b44b",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(data_decomp.keys())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eb4fd845",
   "metadata": {},
   "source": [
    "The most salient information included in this file are the values for the amplitudes, fwhms and means of each fitted Gaussian component. These include,\n",
    "\n",
    "amplitudes_initial, fwhms_initial, means_initial : the parameters of each Gaussian component determined by AGD (each array has length equal to the number of fitted components).\n",
    "amplitudes_fit, fwhms_fit, means_fit : the parameters of each Gaussian component following a least-squares fit of the initial AGD model to the data.\n",
    "amplitudes_fit_err, fwhms_fit_err, means_fit_err : uncertainities in the fitted Gaussian parameters, determined from the least-squares fit.\n",
    "GaussPy also stores the reduced 𝜒2 value from the least-squares fit (rchi2), but this is currently under construction. This value can be computed outside of GaussPy easily.\n",
    "\n",
    "# Plot Decomposition Results\n",
    "\n",
    "The following is an example python script for plotting the original spectrum and GaussPy decomposition results. We must specify the following parameters:\n",
    "\n",
    "FILENAME_DATA: the filename containing the dataset to-be-decomposed.\n",
    "FILENAME_DATA_DECOMP: the filename containing the GaussPy decomposition results.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "060fa164",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot GaussPy results\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import pickle\n",
    "\n",
    "def gaussian(amp, fwhm, mean):\n",
    "    return lambda x: amp * np.exp(-4. * np.log(2) * (x-mean)**2 / fwhm**2)\n",
    "\n",
    "def unravel(list):\n",
    "    return np.array([i for array in list for i in array])\n",
    "\n",
    "FILENAME_DATA = 'simple_gaussian.pickle'\n",
    "FILENAME_DATA_DECOMP = 'simple_gaussian_decomposed.pickle'\n",
    "\n",
    "data = pickle.load(open(FILENAME_DATA, 'rb'))\n",
    "spectrum = unravel(data['data_list'])\n",
    "chan = unravel(data['x_values'])\n",
    "errors = unravel(data['errors'])\n",
    "\n",
    "data_decomp = pickle.load(open(FILENAME_DATA_DECOMP, 'rb'))\n",
    "means_fit = unravel(data_decomp['means_fit'])\n",
    "amps_fit = unravel(data_decomp['amplitudes_fit'])\n",
    "fwhms_fit = unravel(data_decomp['fwhms_fit'])\n",
    "\n",
    "fig = plt.figure()\n",
    "ax = fig.add_subplot(111)\n",
    "\n",
    "model = np.zeros(len(chan))\n",
    "\n",
    "for j in range(len(means_fit)):\n",
    "    component = gaussian(amps_fit[j], fwhms_fit[j], means_fit[j])(chan)\n",
    "    model += component\n",
    "    ax.plot(chan, component, color='red', lw=1.5)\n",
    "\n",
    "ax.plot(chan, spectrum, label='Data', color='black', linewidth=1.5)\n",
    "ax.plot(chan, model, label = r'$\\log\\alpha=1.$', color='purple', linewidth=2.)\n",
    "ax.plot(chan, errors, label = 'Errors', color='green', linestyle='dashed', linewidth=2.)\n",
    "\n",
    "ax.set_xlabel('Channels')\n",
    "ax.set_ylabel('Amplitude')\n",
    "\n",
    "ax.set_xlim(0,len(chan))\n",
    "ax.set_ylim(np.min(spectrum),np.max(spectrum))\n",
    "ax.legend(loc=2)\n",
    "\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e30ff184",
   "metadata": {},
   "source": [
    "The following figure displays the results of the decomposition using the above example python code. Clearly the fit to the simple Gaussian spectrum is good. If we were to vary the value of log𝛼, the fit would not change significantly as the fit to a spectrum containing a single Gaussian funciton does not depend sensitively on the initial guesses, especially because GaussPy performs a least-squares fit after determining initial guesses for the fitted Gaussian parameters with AGD.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "61d2d739",
   "metadata": {},
   "source": [
    "In the ensuing chapters, we will move on from this simple example to consider spectra of increased complexity, as well as the effect of different values of 𝛼 on the decomposition.\n",
    "\n",
    "# Multiple Gaussians Tutorial\n",
    "## Constructing a GaussPy-Friendly Dataset\n",
    "\n",
    "As discussed in the Simple Example Tutorial, before running GaussPy we must ensure that our data is in a format readable by GaussPy. In particular, for each spectrum, we need to provide the independent and dependent spectral arrays (i.e. channels and amplitudes) and an estimate of the uncertainity per channel. In the following example we will construct a spectrum containing multiple overlapping Gaussian components with added spectral noise, using Equation (1), and plot the results.\n",
    "\n",
    "We will make the following choices for parameters in this example:\n",
    "\n",
    "NCOMPS = 3 : to include 3 Gaussian functions in the spectrum\n",
    "AMPS = [3,2,1] : amplitudes of the included Gaussian functions\n",
    "FWHMS = [20,50,40] : FWHM (in channels) of the included Gaussian functions\n",
    "MEANS = [220,250,300] : mean positions (in channels) of the included Gaussian functions\n",
    "NCHANNELS = 512 : number of channels in the spectrum\n",
    "RMS = 0.05 : RMS noise per channel\n",
    "FILENAME : name of file to write output data to\n",
    "The following code provides an example of how to construct a Gaussian function with the above parameters and store it in GaussPy-friendly format.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d7b75c88",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create profile with multiple, blended Gaussians and added noise\n",
    "# Store in format required for GaussPy\n",
    "\n",
    "import numpy as np\n",
    "import pickle\n",
    "\n",
    "def gaussian(amp, fwhm, mean):\n",
    "    return lambda x: amp * np.exp(-4. * np.log(2) * (x-mean)**2 / fwhm**2)\n",
    "\n",
    "# Specify filename of output data\n",
    "FILENAME = 'multiple_gaussians.pickle'\n",
    "\n",
    "# Number of Gaussian functions per spectrum\n",
    "NCOMPS = 3\n",
    "\n",
    "# Component properties\n",
    "AMPS = [3,2,1]\n",
    "FWHMS = [20,50,40] # channels\n",
    "MEANS = [220,250,300] # channels\n",
    "\n",
    "# Data properties\n",
    "RMS = 0.05\n",
    "NCHANNELS = 512\n",
    "\n",
    "# Initialize\n",
    "data = {}\n",
    "chan = np.arange(NCHANNELS)\n",
    "errors = np.ones(NCHANNELS) * RMS\n",
    "\n",
    "spectrum = np.random.randn(NCHANNELS) * RMS\n",
    "\n",
    "# Create spectrum\n",
    "for a, w, m in zip(AMPS, FWHMS, MEANS):\n",
    "    spectrum += gaussian(a, w, m)(chan)\n",
    "\n",
    "# Enter results into AGD dataset\n",
    "data['data_list'] = data.get('data_list', []) + [spectrum]\n",
    "data['x_values'] = data.get('x_values', []) + [chan]\n",
    "data['errors'] = data.get('errors', []) + [errors]\n",
    "\n",
    "pickle.dump(data, open(FILENAME, 'wb'))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ebdd5b7d",
   "metadata": {},
   "source": [
    "## Running GaussPy\n",
    "\n",
    "With our GaussPy-friendly dataset, we can now run GaussPy. As in the Simple Example Tutorial, we begin by selecting a value of 𝛼 to use in the decomposition. In this example, we will select log𝛼=0.5 to begin with. As before, the important parameters to specify are:\n",
    "\n",
    "alpha1: our choice for the value of log𝛼.\n",
    "snr_thresh: the signal-to-noise ratio threshold below which amplitude GaussPy will not fit a component.\n",
    "FILENAME_DATA: the filename containing the dataset to-be-decomposed, constructed above (or any GaussPy-friendly dataset)\n",
    "FILENAME_DATA_DECOMP: the filename to store the decomposition results from GaussPy.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0baabd5b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Decompose multiple Gaussian dataset using AGD\n",
    "import pickle\n",
    "import projet.src.fitters.gausspy_lib.gp as gp\n",
    "\n",
    "# Specify necessary parameters\n",
    "alpha1 = 1\n",
    "snr_thresh = 5.\n",
    "FILENAME_DATA = 'multiple_gaussians.pickle'\n",
    "FILENAME_DATA_DECOMP = 'multiple_gaussians_decomposed.pickle'\n",
    "\n",
    "# Load GaussPy\n",
    "g = gp.GaussianDecomposer()\n",
    "\n",
    "# Setting AGD parameters\n",
    "g.set('phase', 'one')\n",
    "g.set('SNR_thresh', [snr_thresh, snr_thresh])\n",
    "g.set('alpha1', alpha1)\n",
    "\n",
    "# Run GaussPy\n",
    "data_decomp = g.batch_decomposition(FILENAME_DATA)\n",
    "\n",
    "# Save decomposition information\n",
    "pickle.dump(data_decomp, open(FILENAME_DATA_DECOMP, 'wb'))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a09e720a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot GaussPy results\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import pickle\n",
    "\n",
    "def gaussian(amp, fwhm, mean):\n",
    "    return lambda x: amp * np.exp(-4. * np.log(2) * (x-mean)**2 / fwhm**2)\n",
    "\n",
    "def unravel(list):\n",
    "    return np.array([i for array in list for i in array])\n",
    "\n",
    "FILENAME_DATA = 'multiple_gaussians.pickle'\n",
    "FILENAME_DATA_DECOMP = 'multiple_gaussians_decomposed.pickle'\n",
    "\n",
    "data = pickle.load(open(FILENAME_DATA, 'rb'))\n",
    "spectrum = unravel(data['data_list'])\n",
    "chan = unravel(data['x_values'])\n",
    "errors = unravel(data['errors'])\n",
    "\n",
    "data_decomp = pickle.load(open(FILENAME_DATA_DECOMP, 'rb'))\n",
    "means_fit = unravel(data_decomp['means_fit'])\n",
    "amps_fit = unravel(data_decomp['amplitudes_fit'])\n",
    "fwhms_fit = unravel(data_decomp['fwhms_fit'])\n",
    "\n",
    "fig = plt.figure()\n",
    "ax = fig.add_subplot(111)\n",
    "\n",
    "model = np.zeros(len(chan))\n",
    "\n",
    "for j in range(len(means_fit)):\n",
    "    component = gaussian(amps_fit[j], fwhms_fit[j], means_fit[j])(chan)\n",
    "    model += component\n",
    "    ax.plot(chan, component, color='red', lw=1.5)\n",
    "\n",
    "ax.plot(chan, spectrum, label='Data', color='black', linewidth=1.5)\n",
    "ax.plot(chan, model, label = r'$\\log\\alpha=1.$', color='purple', linewidth=2.)\n",
    "ax.plot(chan, errors, label = 'Errors', color='green', linestyle='dashed', linewidth=2.)\n",
    "\n",
    "ax.set_xlabel('Channels')\n",
    "ax.set_ylabel('Amplitude')\n",
    "\n",
    "ax.set_xlim(0,len(chan))\n",
    "ax.set_ylim(np.min(spectrum),np.max(spectrum))\n",
    "ax.legend(loc=2)\n",
    "\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d6a3f47b",
   "metadata": {},
   "source": [
    "These results demonstrate that our choice of 𝛼 has a significant effect on the success of the GaussPy model. In order to select the best value of 𝛼 for a given dataset, we need to train the AGD algorithm using a training set. This process is described in the following section.\n",
    "\n",
    "# Training AGD\n",
    "## Creating a Synthetic Training Dataset\n",
    "\n",
    "To select the optimal value of the smoothing parameter 𝛼, you must train the AGD algorithm using a training dataset with known underlying Gaussian decomposition. In other words, you need to have a dataset for which you know (or have an estimate of) the true Gaussian model. This training dataset can be composed of real (i.e. previously analyzed) or synthetically-constructed data, for which you have prior information about the underlying decomposition. This prior information is used to maximize the model accuracy by calibrating the 𝛼 parameter used by AGD.\n",
    "\n",
    "Training datasets can be constructed by adding Gaussian functions with parameters drawn from known distributions with known uncertainties. For example, we can create a mock dataset with NSPECTRA-realizations of Equation (1).\n",
    "\n",
    "In the next example we will show how to implement this in python. For this example we will construct a synthetic training dataset with parameters similar to those found in the Multiple Gaussians Tutorial example. We must set the following parameters:\n",
    "\n",
    "NOISE∼𝑁(0,RMS)+𝑓×RMS with RMS=0.05 and 𝑓=0\n",
    "NCOMPS = 3\n",
    "NCHANNELS = 512 : the number of channels per spectrum\n",
    "RMS = 0.05 : RMS noise per channel.\n",
    "NSPECTRA = 200 : number of synthetic spectra to create for the training dataset.\n",
    "AMP∼𝜇(0.5,4) : the possible range of amplitudes to be included in each synthetic spectrum. Spectra with a more dominant contribution from the noise can also be generated and used as training sets for AGD.\n",
    "FWHM∼𝜇(20,80) and MEAN∼𝜇(0.25,0.75)×NCHANNELS : the possible range of FWHM and mean positions of Gaussian functions to be included in each synthetic spectrum.\n",
    "TRAINING_SET : True, determines whether the decomposition “true answers” are sorted along with the synthetic spectra for accuracy verification in training.\n",
    "FILENAME : filename for storing the synthetically-constructed data\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a6043d79",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create training dataset with Gaussian profiles\n",
    "\n",
    "import numpy as np\n",
    "import pickle\n",
    "\n",
    "# Specify the number of spectral channels (NCHANNELS)\n",
    "NCHANNELS = 512\n",
    "\n",
    "# Specify the number of spectra (NSPECTRA)\n",
    "NSPECTRA = 200\n",
    "\n",
    "# Estimate of the root-mean-square uncertainty per channel (RMS)\n",
    "RMS = 0.05\n",
    "\n",
    "# Estimate the number of components\n",
    "NCOMPS = 3\n",
    "\n",
    "# Specify the min-max range of possible properties of the Gaussian function paramters:\n",
    "AMP_lims = [0.5, 4]\n",
    "FWHM_lims = [20, 80] # channels\n",
    "MEAN_lims = [0.25*NCHANNELS, 0.75*NCHANNELS] # channels\n",
    "\n",
    "# Indicate whether the data created here will be used as a training set\n",
    "# (a.k.a. decide to store the \"true\" answers or not at the end)\n",
    "TRAINING_SET = True\n",
    "\n",
    "# Specify the pickle file to store the results in\n",
    "FILENAME = 'training_data.pickle'\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "70aa5d40",
   "metadata": {},
   "source": [
    "With the above parameters specified, we can proceed with constructing a set of synthetic training data composed of Gaussian functions with known parameters (i.e., for which we know the “true” decompositon), sampled randomly from the parameter ranges specified above. The resulting data, including the channel values, spectral values and error estimates, are stored in the pickle file specified above with FILENAME. Because we want this to be a training set (TRAINING_SET = True), the true decomposition answers (in the form of amplitudes, FWHM and means for all components) are also stored in the output file. For example, to construct a synthetic dataset:\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "67a495b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create training dataset with Gaussian profiles -cont-\n",
    "\n",
    "# Initialize\n",
    "data = {}\n",
    "chan = np.arange(NCHANNELS)\n",
    "errors = np.ones(NCHANNELS) * RMS\n",
    "\n",
    "# Begin populating data\n",
    "for i in range(NSPECTRA):\n",
    "    spectrum_i = np.random.randn(NCHANNELS) * RMS\n",
    "\n",
    "    amps = []\n",
    "    fwhms = []\n",
    "    means = []\n",
    "\n",
    "    for comp in range(NCOMPS):\n",
    "        # Select random values for components within specified ranges\n",
    "        a = np.random.uniform(AMP_lims[0], AMP_lims[1])\n",
    "        w = np.random.uniform(FWHM_lims[0], FWHM_lims[1])\n",
    "        m = np.random.uniform(MEAN_lims[0], MEAN_lims[1])\n",
    "\n",
    "        # Add Gaussian profile with the above random parameters to the spectrum\n",
    "        spectrum_i += gaussian(a, w, m)(chan)\n",
    "\n",
    "        # Append the parameters to initialized lists for storing\n",
    "        amps.append(a)\n",
    "        fwhms.append(w)\n",
    "        means.append(m)\n",
    "\n",
    "    # Enter results into AGD dataset\n",
    "    data['data_list'] = data.get('data_list', []) + [spectrum_i]\n",
    "    data['x_values'] = data.get('x_values', []) + [chan]\n",
    "    data['errors'] = data.get('errors', []) + [errors]\n",
    "\n",
    "    # If training data, keep answers\n",
    "    if TRAINING_SET:\n",
    "        data['amplitudes'] = data.get('amplitudes', []) + [amps]\n",
    "        data['fwhms'] = data.get('fwhms', []) + [fwhms]\n",
    "        data['means'] = data.get('means', []) + [means]\n",
    "\n",
    "# Dump synthetic data into specified filename\n",
    "pickle.dump(data, open(FILENAME, 'wb'))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "23a14e7f",
   "metadata": {},
   "source": [
    "## Training the Algorithm\n",
    "\n",
    "Next, we will apply GaussPy to the real or synthetic training dataset and compare the results with the known underlying decompositon to determine the optimal value for the smoothing parameter 𝛼. We must set the following parameters\n",
    "\n",
    "FILENAME: the filename of the training dataset in GaussPy-friendly format.\n",
    "snr_thresh: the signal-to-noise threshold below which amplitude GaussPy will not fit components.\n",
    "alpha_initial: initial choice for  log𝛼"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b6811bb2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Select the optimal value of alpha by training the AGD algorithm\n",
    "\n",
    "import projet.src.fitters.gausspy_lib.gp as gp\n",
    "\n",
    "# Set necessary parameters\n",
    "FILENAME = 'training_data.pickle'\n",
    "snr_thresh = 5.\n",
    "alpha_initial = 1.\n",
    "\n",
    "g = gp.GaussianDecomposer()\n",
    "\n",
    "# Next, load the training dataset for analysis:\n",
    "g.load_training_data(FILENAME)\n",
    "\n",
    "# Set GaussPy parameters\n",
    "g.set('phase', 'one')\n",
    "g.set('SNR_thresh', [snr_thresh, snr_thresh])\n",
    "\n",
    "# Train AGD starting with initial guess for alpha\n",
    "g.train(alpha1_initial = alpha_initial)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e8ff28bb",
   "metadata": {},
   "source": [
    " and compare the results with the known underlying decomposition to compute the accuracy of the decomposition. The training process will then iteratively change the value of 𝛼initial and recompute the decomposition until the process converges.The accuracy of the decomposition associated with the converged value of 𝛼 is a description of how well GaussPy can recover the true underlying decomposition.\n",
    "\n",
    "The above training dataset parameters were selected with the Multiple Gaussians Tutorial in mind. As we saw in that example, the choice of 𝛼 has a significant effect on the GaussPy decomposition. In the training above, when we choose an initial value of log𝛼initial=1.0 the training process converges to log𝛼=1.58 with an accuracy of 68.4%, and required 33 iterations.\n",
    "\n",
    "To ensure that the training converges on the optimal value of 𝛼 and not a local maximum, it is useful to re-run the training process for several choices of 𝛼initial. When we run the above example with an initial choice of log𝛼𝑖𝑛𝑖𝑡𝑖𝑎𝑙=3, AGD converges to a value of log𝛼=1.58 with an accuracy of 68.4% and required 33 iterations. However, this is a relatively simple example and therefore the converged value of alpha is not very sensitive to 𝛼initial. In the Prepping a Datacube chapter, we will discuss the effects of added complexity.\n",
    "\n",
    "## Running GaussPy using Trained 𝛼\n",
    "\n",
    "With a trained value of 𝛼 in hand, we can proceed to decompose our target dataset with AGD. In this example, we will return to the example from the Multiple Gaussians Tutorial chapter. Following training, we select a value of log𝛼=1.58, which decomposed our training dataset with an accuracy of 68.4%. As in the Simple Example Tutorial and Multiple Gaussians Tutorial, the important parameters to specify are:\n",
    "\n",
    "alpha1: our choice for the value of log𝛼\n",
    "snr_thresh: the signal-to-noise ratio threshold below which amplitude GaussPy will not fit a component\n",
    "FILENAME_DATA: the filename containing the dataset to-be-decomposed, constructed above (or any GaussPy-friendly dataset)\n",
    "FILENAME_DATA_DECOMP: filename to store the decomposition results from GaussPy\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0052a566",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Decompose multiple Gaussian dataset using AGD with TRAINED alpha\n",
    "import pickle\n",
    "import projet.src.fitters.gausspy_lib.gp as gp\n",
    "\n",
    "# Specify necessary parameters\n",
    "alpha1 = 1.58\n",
    "snr_thresh = 5.\n",
    "\n",
    "FILENAME_DATA = 'multiple_gaussians.pickle'\n",
    "FILENAME_DATA_DECOMP = 'multiple_gaussians_trained_decomposed.pickle'\n",
    "\n",
    "# Load GaussPy\n",
    "g = gp.GaussianDecomposer()\n",
    "\n",
    "# Setting AGD parameters\n",
    "g.set('phase', 'one')\n",
    "g.set('SNR_thresh', [snr_thresh, snr_thresh])\n",
    "g.set('alpha1', alpha1)\n",
    "\n",
    "# Run GaussPy\n",
    "data_decomp = g.batch_decomposition(FILENAME_DATA)\n",
    "print(data_decomp)\n",
    "\n",
    "# Save decomposition information\n",
    "pickle.dump(data_decomp, open(FILENAME_DATA_DECOMP, 'wb'))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8531f9ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot GaussPy results\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import pickle\n",
    "\n",
    "def gaussian(amp, fwhm, mean):\n",
    "    return lambda x: amp * np.exp(-4. * np.log(2) * (x-mean)**2 / fwhm**2)\n",
    "\n",
    "def unravel(list):\n",
    "    return np.array([i for array in list for i in array])\n",
    "\n",
    "FILENAME_DATA = 'multiple_gaussians.pickle'\n",
    "FILENAME_DATA_DECOMP = 'multiple_gaussians_trained_decomposed.pickle'\n",
    "\n",
    "data = pickle.load(open(FILENAME_DATA, 'rb'))\n",
    "spectrum = unravel(data['data_list'])\n",
    "chan = unravel(data['x_values'])\n",
    "errors = unravel(data['errors'])\n",
    "\n",
    "data_decomp = pickle.load(open(FILENAME_DATA_DECOMP, 'rb'))\n",
    "means_fit = unravel(data_decomp['means_fit'])\n",
    "amps_fit = unravel(data_decomp['amplitudes_fit'])\n",
    "fwhms_fit = unravel(data_decomp['fwhms_fit'])\n",
    "\n",
    "fig = plt.figure()\n",
    "ax = fig.add_subplot(111)\n",
    "\n",
    "model = np.zeros(len(chan))\n",
    "\n",
    "for j in range(len(means_fit)):\n",
    "    component = gaussian(amps_fit[j], fwhms_fit[j], means_fit[j])(chan)\n",
    "    model += component\n",
    "    ax.plot(chan, component, color='red', lw=1.5)\n",
    "\n",
    "ax.plot(chan, spectrum, label='Data', color='black', linewidth=1.5)\n",
    "ax.plot(chan, model, label = r'$\\log\\alpha=1.$', color='purple', linewidth=2.)\n",
    "ax.plot(chan, errors, label = 'Errors', color='green', linestyle='dashed', linewidth=2.)\n",
    "\n",
    "ax.set_xlabel('Channels')\n",
    "ax.set_ylabel('Amplitude')\n",
    "\n",
    "ax.set_xlim(0,len(chan))\n",
    "ax.set_ylim(np.min(spectrum),np.max(spectrum))\n",
    "ax.legend(loc=2)\n",
    "\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "628f3e14",
   "metadata": {},
   "source": [
    "# Outside test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "49da7f46",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create training dataset with Gaussian profiles\n",
    "\n",
    "import numpy as np\n",
    "import pickle\n",
    "\n",
    "# Specify the number of spectral channels (NCHANNELS)\n",
    "NCHANNELS = 512\n",
    "\n",
    "# Specify the number of spectra (NSPECTRA)\n",
    "NSPECTRA = 2\n",
    "\n",
    "# Estimate of the root-mean-square uncertainty per channel (RMS)\n",
    "RMS = 0.05\n",
    "\n",
    "# Estimate the number of components\n",
    "NCOMPS = 3\n",
    "\n",
    "# Specify the min-max range of possible properties of the Gaussian function paramters:\n",
    "AMP_lims = [0.5, 4]\n",
    "FWHM_lims = [20, 80] # channels\n",
    "MEAN_lims = [0.25*NCHANNELS, 0.75*NCHANNELS] # channels\n",
    "\n",
    "# Indicate whether the data created here will be used as a training set\n",
    "# (a.k.a. decide to store the \"true\" answers or not at the end)\n",
    "TRAINING_SET = True\n",
    "\n",
    "# Specify the pickle file to store the results in\n",
    "FILENAME = 'training_data_homemade.pickle'\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "15c03174",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create training dataset with Gaussian profiles -cont-\n",
    "\n",
    "# Initialize\n",
    "data = {}\n",
    "chan = np.arange(NCHANNELS)\n",
    "errors = np.ones(NCHANNELS) * RMS\n",
    "\n",
    "# Begin populating data\n",
    "for i in range(NSPECTRA):\n",
    "    spectrum_i = np.random.randn(NCHANNELS) * RMS\n",
    "\n",
    "    amps = []\n",
    "    fwhms = []\n",
    "    means = []\n",
    "\n",
    "    for comp in range(NCOMPS):\n",
    "        # Select random values for components within specified ranges\n",
    "        a = np.random.uniform(AMP_lims[0], AMP_lims[1])\n",
    "        w = np.random.uniform(FWHM_lims[0], FWHM_lims[1])\n",
    "        m = np.random.uniform(MEAN_lims[0], MEAN_lims[1])\n",
    "\n",
    "        # Add Gaussian profile with the above random parameters to the spectrum\n",
    "        spectrum_i += gaussian(a, w, m)(chan)\n",
    "\n",
    "        # Append the parameters to initialized lists for storing\n",
    "        amps.append(a)\n",
    "        fwhms.append(w)\n",
    "        means.append(m)\n",
    "\n",
    "    # Enter results into AGD dataset\n",
    "    data['data_list'] = data.get('data_list', []) + [spectrum_i]\n",
    "    data['x_values'] = data.get('x_values', []) + [chan]\n",
    "    data['errors'] = data.get('errors', []) + [errors]\n",
    "\n",
    "    # If training data, keep answers\n",
    "    if TRAINING_SET:\n",
    "        data['amplitudes'] = data.get('amplitudes', []) + [amps]\n",
    "        data['fwhms'] = data.get('fwhms', []) + [fwhms]\n",
    "        data['means'] = data.get('means', []) + [means]\n",
    "\n",
    "# Dump synthetic data into specified filename\n",
    "pickle.dump(data, open(FILENAME, 'wb'))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f3ecde4a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Select the optimal value of alpha by training the AGD algorithm\n",
    "\n",
    "import projet.src.fitters.gausspy_lib.gp as gp\n",
    "\n",
    "# Set necessary parameters\n",
    "FILENAME = 'training_data_homemade.pickle'\n",
    "snr_thresh = 5.\n",
    "alpha_initial = 1.\n",
    "\n",
    "g = gp.GaussianDecomposer()\n",
    "\n",
    "# Next, load the training dataset for analysis:\n",
    "g.load_training_data(FILENAME)\n",
    "\n",
    "# Set GaussPy parameters\n",
    "g.set('phase', 'one')\n",
    "g.set('SNR_thresh', [snr_thresh, snr_thresh])\n",
    "\n",
    "# Train AGD starting with initial guess for alpha\n",
    "g.train(alpha1_initial = alpha_initial)\n",
    "print(g.p[\"alpha1\"],\n",
    "            g.p[\"alpha2\"],\n",
    "            g.p[\"training_results\"],)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
